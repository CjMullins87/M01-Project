{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "## Reviewing the Process\n",
    "\n",
    "After first normalizing our `Price` variable through a log transform, I determined that several instances of multicoloinearity existed. As `grade` had the highest Pearson coefficient with our desired `pricelog` variable, when I began to deselect possible variables to incorporate, I deselected those which had a high correlation with `grade`.\n",
    "\n",
    "To select variables from the subset, I made use of SciKit Learn's recursive feature elimination, which deselects variables with smaller coefficients in favor of those with more impact. Through this method, I selected `grade`, `waterfront`, `bathrooms`, `condition`, and `lat`. I tested this proposed model with StatsModels and obtained an $R^2$ of 0.68. Through trial and error, I found that adding `yr_built` increased $R^2$ to 0.72, and decided to incorporate it.\n",
    "\n",
    "To check for overfitting, I ran the proposed model again through SciKit Learn's train-test split and found that the proposed model returned similar MSE values on both the train and test set, suggesting that the model wasn't overfit; and I found that the $R^2$ regularly sat above 0.70, suggesting it kept the previously observed fit. I further used SciKit Learn and MatplotLib to test the distribution of our residuals on both the train and test sets and found that the distribution of both was normal and fit the assumption of homoscedacticity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Final Model\n",
    "\n",
    "> $ln(Price) = \\alpha (Grade) + \n",
    "              \\beta (Latitude) + \n",
    "              \\gamma (Waterfront) + \n",
    "              \\delta (Condition) + \n",
    "              \\epsilon (Bathrooms) + \n",
    "              \\zeta (Year Built) +\n",
    "              Intercept$ \n",
    "\n",
    "Having confirmed that our final model met the requirements of linearity, normality of residuals, and homoscedasticity, I pulled the coefficients and intercept from SciKitLearn and StatsModels to arrive at the following expression:\n",
    "\n",
    ">$ln(Price) = \\frac {133}{500}\\ Grade + \n",
    "              \\frac {162}{125}\\ Latitude + \n",
    "              \\frac {81}{125}\\ Waterfront + \n",
    "              \\frac {77}{1250}\\ Condition + \n",
    "              \\frac {187}{1000}\\ Bathrooms - \n",
    "              \\frac {1}{250} Year Built -\n",
    "              42.651$\n",
    "\n",
    "<sub>Coefficient values represented as fractions are approximate</sub>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the Model\n",
    "\n",
    "### The Value of Latitude\n",
    "\n",
    "`latitude` has the largest coefficient, but `grade` has stronger correlation to our desired variable. This is primarily driven by the fact that `latitude` is incremental on a very, very small scale. As you can see on the maps derived in the prior notebook, the entirety of King County only spans the latitude of about 47.1N to 47.8N - in other words, it's possible to travel across the entire county and only move up 0.7 degrees, so, it needs a bigger bolster for those incremental changes to have meaning.\n",
    "\n",
    "`latitude` is also important to King County in that, simply put, the farther north you go, the closer you are to Seattle's CBD, and the closer you get to downtown Seattle, the higher your average price. **All things being equal, the same house from south King County will sell for \\$150K more if it's sharing the same latitude as downtown Seattle.**\n",
    "\n",
    "![](images/pricescattersmall.png)\n",
    "\n",
    "### Waterfront Views\n",
    "\n",
    "Reviewing several test houses at multiple latitudes, waterfront views are implied to be very lucrative. **Fairly consistently, the model predicted that average grade houses could double in sale price as long as they had access to a waterfront view.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The \"Year Built\" Coeffecient\n",
    "\n",
    "This negative coefficient scales with the year the house was built, suggesting that newer houses suffer a negligible penalty. This is likely due to the fact that as time has passed, the city has spread out, and newer houses are farther away from the urban center - whereas older houses are much closer. As you can see in the scatter plot below, older houses are clustered much closer to downtown, whereas newer houses are farther out, and as a general rule, house values increase as you approach downtown.\n",
    "\n",
    "![](images/yrbuilt.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The County Grading System\n",
    "\n",
    "The county's grading system is wholistic:  meaning it takes into account square footage, construction techniquess and methods, materials used and their quality, as well as the quality of house design. Since it takes so much into account, it actually ranks houses on a scale of one (ranked \"Cabin\") to 13 (ranked \"Mansion\") and this seems to adequately capture price variation as a function of quality. In total, an average house is ranked as a seven. **For that same average house, the difference between a grade of seven and a grade of eight is worth about $50K.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
